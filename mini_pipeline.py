# -----------------------------------------------
# Step 1â€“2: Load Code Snippets and Embed with CodeBERT
# -----------------------------------------------

from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import numpy as np

# Step 1: Load dataset
print("ğŸ“¦ Loading dataset...")
raw_dataset = load_dataset("ZorraZabb/full_coding_sampling_xml_fitered")

# Check for split
if isinstance(raw_dataset, dict) and "train" in raw_dataset:
    dataset = raw_dataset["train"]
else:
    dataset = raw_dataset

# Select first 10 samples
try:
    dataset_10 = dataset.select(range(10))
except AttributeError:
    # If select is not available, fallback to slicing
    dataset_10 = dataset[:10]

# Inspect field names
print("âœ… Dataset fields:", list(dataset_10[0].keys()))

# Step 2: Extract just the raw code
code_samples = [item["text"] for item in dataset_10]

print(f"\nğŸ§ª Loaded {len(code_samples)} code snippets.")

# Step 3: Load CodeBERT for code embeddings
print("\nğŸ¤– Loading CodeBERT model...")
code_embedder = SentenceTransformer("microsoft/codebert-base")

# Step 4: Generate embeddings for each code snippet
print("ğŸ“ Generating embeddings...")
code_vectors = code_embedder.encode(code_samples)

# Step 5: Show embedding shape
print("\nğŸ” First embedding vector (first 10 values):")
print(code_vectors[0][:10])
print("â¡ï¸ Vector dimension:", len(code_vectors[0]))

# Step 6: Save embeddings (optional for future use)
np.save("codebert_embeddings.npy", code_vectors)

print("\nâœ… Success! You now have embedded code vectors.")